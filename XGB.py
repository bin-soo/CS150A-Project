import pandas as pd
import numpy as np
from sklearn.model_selection import KFold,GroupKFold
import xgboost as xgb
from xgboost import plot_importance
from dataSeperation import sample2,trainx2,trainy2,trainxs,trainys
def rmse(y1,y2):
    return np.sqrt(((y1 - y2) ** 2).mean())
trainx = trainxs
trainy = trainys
xgb = xgb.XGBClassifier(max_depth=14, learning_rate=0.12, n_estimators=600, objective='binary:logistic',
                          random_state=42)
rmseList = []
for kfold, (train, val) in enumerate(KFold(n_splits=5,shuffle=True,random_state=42)\
                                              .split(trainx, trainy)):

    X_train, X_val = trainx.iloc[train], trainx.iloc[val]
    y_train, y_val = trainy.iloc[train], trainy.iloc[val]
    xgb.fit(X_train,y_train)
    y_pred = xgb.predict(X_val)
    rmseList.append(rmse(y_pred,y_val))
print('rmse of val: ',rmseList,'\nmean: ',np.mean(rmseList))

'''
depth = 0.7, lr=0.08, n=200:
rmse of val:  [0.4002390056827559, 0.39866664815721725, 0.40782578753152293, 0.41062120920115386, 0.4104773117225855] 
 mean:  0.405565992459047
 
 200 0.08 7
 rmse of val:  [0.4166533331199932, 0.41255302689472534, 0.4148493702538308, 0.4124722212868805, 0.4143267631552018]
mean:  0.41417094294212636

300 0.08 7
rmse of val:  [0.413924308700677, 0.4102844541697057, 0.41340053217188777, 0.40987803063838396, 0.4129568177586288]
mean:  0.4120888286878567

300 0.12 7
rmse of val:  [0.412674205639267, 0.4102438299353203, 0.41008129275384736, 0.4089009660052174, 0.4113797920818831]
mean:  0.410656017283107

300 0.12 10
rmse of val:  [0.4112177038990418, 0.40644802865803153, 0.4079624165696312, 0.41032507438208876, 0.4074309757492673]
mean:  0.4086768398516121

500 0.12 10
rmse of val:  [0.41158231254513356, 0.40591460514086786, 0.407635458058627, 0.4086155487333622, 0.4091861841916627]
mean:  0.4085868217339307

500 0.15 10
rmse of val:  [0.4131182235954578, 0.40718546143004664, 0.41182520563948, 0.4113392760240626, 0.4119465984809196]
mean:  0.4110829530339933

500 0.1 10
rmse of val:  [0.4105687112611806, 0.40632499307820086, 0.4087786687193939, 0.40845236360355824, 0.4095932942159413]
mean:  0.40874360617565497

700 0.12 10
rmse of val:  [0.41162280468085505, 0.40841155713324273, 0.4093490767873633, 0.411258231933822, 0.41008129275384736]
mean:  0.4101445926578261

500 0.13 10
rmse of val:  [0.4129971751315821, 0.40677594160258135, 0.4107716316073121, 0.40767634221279014, 0.40987803063838396]
mean:  0.4096198242385299

500 0.11 10
rmse of val:  [0.410731055558257, 0.4068988408273814, 0.4095526014242045, 0.41, 0.4115013163202924]
mean:  0.40973676282602706

600 0.12 10
rmse of val:  [0.4111366358442572, 0.4069397989875161, 0.4079624165696312, 0.4107716316073121, 0.40947120370871826]
mean:  0.409256337343487

600 0.12 14
rmse of val:  [0.41844951905815353, 0.40914545090957566, 0.41396457175302653, 0.4164132562731403, 0.4152107898405339]
mean:  0.41463671756688597

750 0.15 10
rmse of val:  [0.4120679555607303, 0.4089009660052174, 0.4089009660052174, 0.41210839997909937, 0.41016256939576207]
mean:  0.41042817138920534

'''
